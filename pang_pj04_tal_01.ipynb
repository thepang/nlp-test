{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mongo_work  as mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For long running queries so I can be notified when it finishes\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = 'me-too.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "I will be analyzing transcripts from the _This American Life podcasts_. All the code for getting the data is in 'scraping.py' for review. I will start from the text preprossing part of the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data from Mongo\n",
    "\n",
    "The data is stored in a local mongo database. You can review the mongo_work.py for the logic to put data into my local database and the logic to pull data from the database into a pandas dataframe as shown in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_num</th>\n",
       "      <th>ep_title</th>\n",
       "      <th>ep_air_date</th>\n",
       "      <th>ep_summary</th>\n",
       "      <th>speaker</th>\n",
       "      <th>words</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120337</th>\n",
       "      <td>464</td>\n",
       "      <td>Invisible Made Visible</td>\n",
       "      <td>May 18, 2012</td>\n",
       "      <td>David Sedaris, Tig Notaro, Ryan Knighton, and ...</td>\n",
       "      <td>Ira Glass</td>\n",
       "      <td>This American Life                          is...</td>\n",
       "      <td>00:56:12_15</td>\n",
       "      <td>Act Four: Turn Around Bright Eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25891</th>\n",
       "      <td>53</td>\n",
       "      <td>Valentine’s Day ‘97</td>\n",
       "      <td>Feb. 7, 1997</td>\n",
       "      <td>Stories about our parents falling in love.</td>\n",
       "      <td>Brett Leveridge</td>\n",
       "      <td>Soon, Dad felt a tap, tap, tap upon his should...</td>\n",
       "      <td>00:31:02_03</td>\n",
       "      <td>Act Three: It's Not the Heat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45522</th>\n",
       "      <td>172</td>\n",
       "      <td>24 Hours at the Golden Apple</td>\n",
       "      <td>Nov. 17, 2000</td>\n",
       "      <td>One day in a Chicago diner.</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>[LAUGHS] You can't go anywhere? Get in the car.</td>\n",
       "      <td>00:40:42_20</td>\n",
       "      <td>Act 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ep_num                      ep_title    ep_air_date  \\\n",
       "120337    464        Invisible Made Visible   May 18, 2012   \n",
       "25891      53           Valentine’s Day ‘97   Feb. 7, 1997   \n",
       "45522     172  24 Hours at the Golden Apple  Nov. 17, 2000   \n",
       "\n",
       "                                               ep_summary          speaker  \\\n",
       "120337  David Sedaris, Tig Notaro, Ryan Knighton, and ...        Ira Glass   \n",
       "25891          Stories about our parents falling in love.  Brett Leveridge   \n",
       "45522                         One day in a Chicago diner.         Danielle   \n",
       "\n",
       "                                                    words    timestamp  \\\n",
       "120337  This American Life                          is...  00:56:12_15   \n",
       "25891   Soon, Dad felt a tap, tap, tap upon his should...  00:31:02_03   \n",
       "45522     [LAUGHS] You can't go anywhere? Get in the car.  00:40:42_20   \n",
       "\n",
       "                                      act  \n",
       "120337  Act Four: Turn Around Bright Eyes  \n",
       "25891        Act Three: It's Not the Heat  \n",
       "45522                               Act 2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = mon.get_episodes()\n",
    "full_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words = full_data['words']\n",
    "\n",
    "# For now, group words by podcast episode\n",
    "words = full_data.groupby(by='ep_num').sum()['words']\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "As recommended, we first remove all numbers/punctuation and lower all capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ep_num\n",
       "380    a couple years ago i interviewed this cop abou...\n",
       "307    ok  this happens to be chicago  but every city...\n",
       "211    when you name names  when you snitch  when you...\n",
       "319    well  i hold in my hand a ghost story that com...\n",
       "25     the story goes like this  recently i heard abo...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "words = words.map(alphanumeric).map(punc_lower)\n",
    "words.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickling for later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('post_data_clean_podcast_words.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(words, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('post_data_clean_podcast_words.pickle','rb') as read_file:\n",
    "    words = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: There are words bracketed like [SPEAKING SPANISH]. What do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document term matrix format\n",
    "\n",
    "Now we remove all stop words and convert to document term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer (and removing stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the typical list of English stop words\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['just'])\n",
    "\n",
    "cv1 = CountVectorizer(stop_words=stop_words, max_df=.9, min_df=.3)\n",
    "transformed_matrix = cv1.fit_transform(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = matutils.Sparse2Corpus(transformed_matrix)\n",
    "id2word = dict((v, k) for k, v in cv1.vocabulary_.items())\n",
    "\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=2, id2word=id2word, passes=60)\n",
    "lda.print_topics()\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"clear\" + 0.003*\"light\" + 0.003*\"hell\" + 0.003*\"close\" + 0.002*\"led\" + 0.002*\"movie\" + 0.002*\"eye\" + 0.002*\"outside\" + 0.002*\"including\" + 0.002*\"post\"'),\n",
       " (1,\n",
       "  '0.004*\"perfectly\" + 0.004*\"laughs\" + 0.004*\"lost\" + 0.004*\"huh\" + 0.004*\"opportunity\" + 0.004*\"closed\" + 0.004*\"needs\" + 0.004*\"making\" + 0.004*\"fear\" + 0.004*\"game\"')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "word_count_array = pd.DataFrame(transformed_matrix.toarray(), columns=cv1.get_feature_names())\n",
    "subset = word_count_array.head(80000)\n",
    "km = KMeans(n_clusters=20)\n",
    "km.fit(subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-test]",
   "language": "python",
   "name": "conda-env-nlp-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
